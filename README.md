Repository Overview

This repository hosts the analysis files for the comparative study on the reliability and similarity of large language models (LLMs) in software development. The study evaluates five LLMs - ChatGPT, Claude, Copilot, Gemini, and Meta - across two distinct case studies: a Food Order and Delivery System (FODS) and a Smart Wallet System (SWS). Each model's performance is scrutinized through the lens of reliability and similarity across various software development activities.

Folder Structure

•	FODS: Case study on the Food Order and Delivery System.
  •	ChatGPT: Contains analysis files of ChatGPT's reliability.
    •	ChatGPT-transcript.pdf: Transcript containing the output of ChatGPT.
    •	ChatGPT-reliability.pdf: Analysis of the transcript for reliability assessment.
  •	Claude: Similar structure as ChatGPT.
    •	Claude -transcript.pdf: Transcript containing the output of Claude.
    •	Claude -reliability.pdf: Analysis of the transcript for reliability assessment.
  •	Copilot: Similar structure as ChatGPT.
    •	Copilot -transcript.pdf: Transcript containing the output of Copilot.
    •	Copilot -reliability.pdf: Analysis of the transcript for reliability assessment.
  •	Gemini: Similar structure as ChatGPT.
    •	Gemini -transcript.pdf: Transcript containing the output of Gemini.
    •	Gemini -reliability.pdf: Analysis of the transcript for reliability assessment.
  •	Meta: Similar structure as ChatGPT.
    •	Meta -transcript.pdf: Transcript containing the output of Meta.
    •	Meta -reliability.pdf: Analysis of the transcript for reliability assessment.
  •	similarity: Contains a single file.
    •	similarity.pdf: Analysis of the similarity of all models in the FODS case.

•	SWS: Case study on the Smart Wallet System.
  •	Similar sub-folder structure as FODS for each LLM.
  •	Each model's folder contains two files: one for the transcript and another for reliability analysis.
  •	similarity: Contains a single file.
  •	similarity.pdf: Analysis of the similarity of all models in the SWS case.

Analysis Overview

Each LLM's folder within the case study directories contains:
•	A transcript PDF file that documents the outputs produced by the model for the specific case.
•	A reliability analysis PDF file that evaluates these outputs in terms of software engineering reliability.
The similarity folder in each case directory provides a comprehensive analysis of how similar the outputs of the different LLMs are when applied to the same software development tasks.

Contributing

We welcome contributions from the community to enhance the analysis and interpretations provided in this repository. Please follow the standard fork-and-pull request workflow if you have suggestions for improvements.

License

This repository is released under the MIT License.

Citation

If you use the data or findings from this repository in your research, please cite:
Kim, Dae-Kyoo, Ming, Hua. (2024). Comparative Analysis of Reliability and Similarity in Large Language Models for Software Development: Case Studies. Preprint submitted to Information and Software Technology.

Contact

For any additional questions or comments, please contact kim2@oakland.edu.
